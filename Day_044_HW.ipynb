{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "確保你了解隨機森林模型中每個超參數的意義，並觀察調整超參數對結果的影響"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 RandomForestClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "\n",
    "Ans. 嘗試改變gini為entropy, 在Accuracy上沒有變化。 而更換參數中estimators和max depth則會。\n",
    "\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型與決策樹的結果進行比較\n",
    "\n",
    "Ans. 使用wine資料, 兩種模型皆出現Overfitting的情況。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy example: 0.9736842105263158 \n",
      "Feature importance: [0.06928636 0.00686495 0.49205258 0.43179611]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.25, random_state = 4)\n",
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 4)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy example:\", metrics.accuracy_score(y_test, y_pred), \n",
    "      \"\\nFeature importance:\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy entropy: 0.9736842105263158 \n",
      "Feature importance: [0.07856459 0.01205124 0.52863788 0.3807463 ]\n"
     ]
    }
   ],
   "source": [
    "# Parameter change\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 4, criterion = \"entropy\")\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy entropy:\", metrics.accuracy_score(y_test, y_pred),\n",
    "      \"\\nFeature importance:\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after parameter change: 0.9111111111111111 \n",
      "Feature importance: [0.04863945 0.03341402 0.         0.         0.         0.039414\n",
      " 0.06236547 0.         0.         0.20711916 0.10071901 0.15216038\n",
      " 0.35616851]\n"
     ]
    }
   ],
   "source": [
    "# Parameter change 2\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 10, max_depth = 2)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy after parameter change:\", metrics.accuracy_score(y_test, y_pred),\n",
    "      \"\\nFeature importance:\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy classifier: 1.0 \n",
      "Feature importance: [0.15361737 0.05327877 0.01730912 0.01904143 0.0219767  0.0325459\n",
      " 0.09285924 0.00882789 0.05530085 0.20036354 0.06139611 0.09478267\n",
      " 0.18870038]\n"
     ]
    }
   ],
   "source": [
    "# Different Dataset & random forest model\n",
    "\n",
    "wine = datasets.load_wine()\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size = 0.25, random_state = 4)\n",
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 4)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy classifier:\", metrics.accuracy_score(y_test, y_pred), \n",
    "      \"\\nFeature importance:\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy regressor: 1.0 \n",
      "Feature importance: [0.169366   0.03215968 0.01489376 0.04624896 0.04499078 0.04629003\n",
      " 0.0714435  0.00578119 0.00841192 0.10825369 0.10657431 0.13753359\n",
      " 0.20805261]\n"
     ]
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size = 0.25, random_state = 4)\n",
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 4)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy regressor:\", metrics.accuracy_score(y_test, y_pred), \n",
    "      \"\\nFeature importance:\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
